\section{Revisão}

% Aqui deve conter:
% \begin{itemize}
%     \item uma revisão da teoria necessária para entender o artigo;
%     \item se possível, um histórico das soluções, ou uma taxonomia.\\
% \end{itemize}


Esta seção destina-se a fazer uma breve analise da literatura sobre o tema de \textit{fake news} e tem como objetivo identificar quais são os algoritmos de \textit{machine learning} e técnicas de \textit{NLP} que estão sendo utilizados para atacar esse problema.

Em \cite {} On the Origin, Proliferation and Tone of Fake News, os autores definiram três hipóteses com foco em aprender e entender a origem, disseminação e tom das notícias falsas. Os resultados dessas hipóteses sugerem o seguinte: 1) as notícias falsas não são publicadas em sites populares, mas sim em veículos ou sites menos conhecidos; 2) notícias falsas são mais disseminadas por usuários não verificados do que por usuários verificados; e 3) as notícias falsas são escritas em um tom linguístico específico, embora seja inconclusivo dizer qual (negativo, positivo ou neutro). O resultado da terceira hipotese pode nos fazer indagar sobre se o uso da analise de sentimentos poderia, de alguma forma, nos auxiliar na deteccao de \textit{fake news}. Entretanto, em \citet{baarir2020} foi mostrado que utilizar o sentimento presente no texto nao auxilia na deteccao de \textit{fake news} pois, segundo eles, uma notícia ter um sentimento positivo ou negativo não está relacionado com a veracidade de sua informação. Logo essa simples distincao entre sentimento negativo, positivo ou neutro nao e o bastante para a deteccao de \textit{fake news}.


Em \cite{} An Explainable Fake News Detector Based on Named Entity Recognition and Stance Classification Applied to COVID-19, os autores criaram um modelo que utilizava \textit{stance detection} para auxiliar o algoritmo de detecção de \textit{fake news}, O modelo consistia dos seguintes passos: (i) O usuário submetia uma \textit{query} a ser categorizada em uma macro-categoria e baseado no resultado desta classificação o sistema selecionava apenas os artigos relevantes para esse tópico específico; (ii) Uma sub-categoria era assinalada para a \textit{query} com o propósito de reduzir ainda mais o número de doumentos que contribuirão para a avaliação; (iii) O modelo utilizava reconhecimento de entidades nomeadas (\textit{NER}) para filtrar os documentos; (iv) Por fim a \textit{query} era comparada com os documentos relevantes utilizando \textit{embedding} e similaridade de cosenos e os top-k documentos mais similares eram utilizados para \textit{stance classification}. Entretanto os autores descobriram que \textit{stance detection} não ajuda na detecção de \textit{fake news}.

\cite{} SAFS: Social-Article Features-Stacking Model for Fake News Detection, e \cite{} Deep learning for fake news detection in a pairwise textual input schema combinaram técnicas de \textit{NLP} com \textit{features} oriundas das redes sociais, como por exemplo, \textit{Graph Embedding technique (GEB)} que representa a disseminação da notícia na rede, data da criação da conta do usuário que esta disseminando a notícia, numero de seguidores desse usuário, data do tweet, quantidade de retweets, quantidade de urls presentes no tweet, etc. Esses trabalhos mostraram que \textit{features} oriundas das redes sociais ajudam na detecção de \textit{fake news}.

Em \cite{} A Novel Score-Based Multi-Source Fake News Detection using Gradient Boosting Algorithm os autores propuseram uma estrutura de definição de metas para detectar as \textit{fake news} que consistia das seguintes etapas: (i) Para extrair os recursos baseados em texto de nível superior de artigos de notícias genuínos e falsos usando TF-IDF; (ii) Extrair os recursos site\_url de site\_url (domínio); (iii) Estimar uma pontuação de credibilidade de recursos de URL no site baseados em várias fontes e, por fim, (iv) Estimar a credibilidade das notícias integrando os recursos baseados em texto e os Pontuações de Credibilidade. Os autores realizaram experimentos com diversos algoritmos como : SVM, KNN, Naïve Bayes, Logistic Regression, Random Forest, AdaBoost, Decision Tree e, por fim, Gradient Boosting que obteve o melhor resultado com uma acuracia de 99.5%.

\cite{}Deep learning for fake news detection in a pairwise textual input schema  Criaram um modelo de deep learning que utiliza (i) features linguisticas como: Numero de palavras, Num silabas, quantidade media de silabas, quantidade media de palavras por frase, quantidade de palavras grandes, quantidade de frases longas, quantidade de frases crutas, quantidade de frases na noticia, taxa de adverbios e adjetivos; (ii) Baseado em informações do usuario como: Id do usuario, quantidade de seguidores, numero de pessoas que o usuario segue, data da criacao da conta, data do tweet, quantidade de likes, quantidade de retweets, Numero URLs. Segundo os autores, o alto desempenho da detecção de notícias falsas na literatura depende em grande parte da exploração de recursos exclusivamente baseados em contas de usuarios ou na exploração de recursos exclusivamente linguísticos. Em contrapartida, esse trabalho dá grande ênfase ao uso de entrada multimodal que varia de incorporação de palavras derivadas automaticamente de texto não estruturado a recursos morfológicos e baseados em string (número de sílabas, número de frases longas, etc.), e de recursos linguísticos de nível superior (como o nível Flesh-Kincaid, a taxa de advérbios-adjetivos etc.).

\cite{} Certain Investigation of Fake News Detection from Facebook and Twitter Using Artificial Intelligence Approach construíram um \textit{dataset} relacionado ao tema de publicidade e avaliaram o dataset com modelos de aprendizado de maquina e técnicas de \textit{NLP} tais como, TF-IDF, BoW, n-gram (1-GRAM ATE 4-GRAM). Esse trabalho mostrou que o uso de N-grams auxilia no processo de deteccao de \textit{fake news}.