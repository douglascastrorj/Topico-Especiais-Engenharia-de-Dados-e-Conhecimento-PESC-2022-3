\section{Revisão Informal}

Nesta seção, serão discutidos alguns trabalhos relacionados ao tema de
categorização fake news de modo a entender quais são abordagens que estão sendo
propostas na literatura, a qualidade dos resultados obtidos por estes, como também, os possíveis impactos sociais, políticos e econômicos que podem ser causados pela disseminação desse tipo de conteúdo.

\subsection{\textit{A Survey on Natural Language Processing for Fake News Detection}}

Em \cite{oshikawa2020} os autores conduziram uma pesquisa sobre processamento de linguagem natural para detecção de notícias falsas em que eles forneceram uma visão geral dos esforços de pesquisa para detecção de notícias falsas e uma comparação sistemática de suas definições de tarefas, conjuntos de dados, construção de modelos, e performances. Em suma, suas contribuições gerias foram as seguintes: \\

\begin{enumerate}
    \item Fornecer uma revisão das soluções de processamento de linguagem natural para detecção atumática de notícias falsas.
    
    \item Analisar sistematicamente como a detecção de notícias falsas estão alinhadas com as tarefas de \textit{NLP} existentes e discutiram as suposições e questões notáveis para diferentes fórmulações do problema;
    
    \item Categorizar e resumir os \textit{datasets} disponíveis, abordagens de \textit{NLP} e resultados, fornecendo experiências em primeira mão e introduções acessíveis para novos pesquisadores interessado neste problema.
\end{enumerate}

\subsubsection{Problemas Relacionados a detecção de \textit{fake news}}

A respeito de problemas relacionados a detecção automática de \textit{fake news}, os autores destacaram 4 que são eles: \\

\textbf{\textit{Fact-Checking}} Em geral, detecção de \textit{fake news} usualmente foca em eventos novos enquanto \textit{fact-checking} é mais amplo. Vale resaltar que, segundo os autores, muitos pesquisadores não distinguem detecção de \textit{fake news} e \textit{fact-checking} pois ambos visam avaliar a veracidade de alegações;  \\

\textbf{\textit{Rumor Detection}} Não há uma definição consistente de detecção de rumor. Uma pesquisa recente (\cite{zubiaga2018}) define detecção de boatos como separar declarações pessoais em boatos ou não boatos, onde o boato é definido como uma declaração que consiste em informações não verificadas no momento da postagem. Dentro de outras palavras, o boato deve conter informações que possam ser verificados em vez de opiniões ou sentimentos subjetivos; \\


\textbf{\textit{Stance Detection}} é definida como a tarefa de aferir de qual lado de um debate um autor está no texto. Isto difere de detecção de \textit{fake news} no sentido que não se trata sobre a veracidade mas da consistência. \textit{Stance Detection} pode ser uma subtarefa de detecção de \textit{fake news} pois ela pode ser aplicada para buscar documentos para evidência; \\


\textbf{\textit{Sentiment Analysis}} A análise de sentimentos é a tarefa de extrair emoções, como impressão favorável ou desfavorável dos clientes de um restaurante. Diferente da detecção de boatos e de notícias falsas, a análise de sentimento não é fazer uma verificação objetiva de alegações, mas para analisar as emoções pessoais. \\


\subsubsection{Formulações das tarefas}

Existem diferentes tipos de estratégias de rotular ou avaliar a detecção de \textit{fake news}. Na maior parte dos estudos, a Detecção de \textit{Fake News} é formulada como um problema de classificão ou de regressão, entretanto a abordagem do problema de classificação é mais frequentemente utilizada. \\

\textbf{Classificação} A maneira mais comum de formular o problema de detecção de \textit{fake news} é como um problema de classificação binária. Todavia, categorizar todas as notícias dentro de apenas duas classes (\textit{fake} ou \textit{real}) é difícil devido a existência de casos em que uma notícia pode ser parcialmente verdadeira e, simultâneamente, parcialmente falsa. Para endereçar este problema, acrescentar classes adcionais é uma prática comum. Principalmente, uma categoria para \textit{fake news} que não são  completamente verdadeiras ou completamente falsas, ou então são inseridos categorias para representar diferentes graus de veracidade que as notícias podem conter. \\


\textbf{Regressão} A Detecção de \textit{fake news} também pode ser formulada como uma tarefa de regressão, onde a saída será uma pontuação numérica que representa a veracidade da informação. Esta abordagem é utlizada por \cite{nakashole2014}. Geralmente, a avaliação é feita através do calculo da diferença entre as pontuações preditas e o piso da pontuação de veracidade ou então usando, \textit{Correlações de Pearson/Spearman}. No entanto, uma vez que os conjuntos de dados disponíveis possuem pontuações discretizadas de veracidade, o desafio aqui é como converter os rótulos discretos para pontuações méricas continuas. \\


\subsection{Social Media and Fake News in the 2016 Election}

\subsubsection{Definição}

\cite{allcot2017} Definiram "\textit{fake news}" como artigos que são intencionalmente e verificavelmente falsos, e podem enganar os leitores. Esta definição inclui artigos fabricados intencionalmentes por websites como por exemplo \textit{denverguardian.com} como também artigos oriundos de \textit{websites} satíricos que podem ser mal interpretados como fatuais, especialmente quando vistos isolados nas redes sociais como no \textit{Twitter} ou \textit{Facebook}. Esta definição exclui diversos "parentes próximos" de \textit{fake news} como por exemplo:

\begin{enumerate}
    \item Erros não intencionais de relatórios;
    \item Rumores que não se originam de uma determinada notícia;
    \item Teorias da conspiração (estas são, por definição, difíceis de verificar como verdadeiras ou falsas, e são tipicamente originadas por pessoas que acreditam que elas sejam verdadeiras);
    \item Sátira, que dificilmente será interpretado erroneamente como fatual;
    \item Declarações falsas de políticos;
    \item Relatórios que são enviesados ou enganosos, mas não totalmente falsos.
\end{enumerate}


\subsubsection{Quem produz \textit{fake news}?}

Parecem existir duas motivações principais para disseminação de \textit{fake news}. A primeira é pecuniária: artigos de notícias que se tornam virais nas mídias sociais podem atrair anúncios significativos aumentar a receita quando os usuários clicam no site original. Esta parece ter sido a principal motivação para a maioria dos produtores cujas identidades foram reveladas. A segunda motivação é ideológica. Alguns provedores de notícias falsas procuram avançar os candidatos que preferem.


\subsubsection{Um Modelo de \textit{Fake News}}

De forma mais ampla, como \textit{fake news} diferem de dados tendenciosos ou enviesados? é uma forma inócua de entretenimento, como filmes de ficção ou romances? Ou têm maiores custos sociais? 

Para responder a estas pergntas, \cite{allcot2017} esboçaram um modelo baseado de demanda por notícias baseado em um modelo desenvolvido formalmente em \cite{gentzkow2016}. \\

Existem dois possíveis estados não observados do mundo, que podem representar se um candidato de esquerda ou de direita terá melhor desempenho no cargo. Empresas de mídia recebem sinais que são informativos sobre o estado verdadeiro e podem diferir na
precisão desses sinais. Também podemos imaginar que as empresas podem fazer investimentos dispendiosos para aumentar a precisão desses sinais. Cada empresa tem uma estratégia de relatórios que mapeia desde os sinais que recebe até as notícias que publica. Empresas pode decidir relatar os sinais com veracidade ou, alternativamente, adicionar viés aos relatórios. \\

No modelo proposto, os consumidores devem escolher uma ação, que poderia
representam defender ou votar em um candidato, e recebem benefícios privados se
eles escolhem o candidato que prefeririam se estivessem plenamente informados. Segundo,
consumidores podem derivar utilidade psicológica de ver relatórios que são consistentes
com suas ideologias. Os consumidores escolhem as empresas das quais consumirão notícias
para maximizar sua própria utilidade esperada. Eles então usam o conteúdo das notícias que consumiram para formar um conceito sobre o estado do mundo. \\

Nesse modelo, dois incentivos distintos podem levar as empresas a distorcer seus relatórios na direção das ideologias dos consumidores. Primeiro, quando o feedback sobre o verdadeiro estado é limitado,
consumidores racionais julgarão uma empresa de melhor qualidade quando seus relatórios estiverem mais próximos
de suas ideologias. Em segundo lugar, os consumidores podem preferir relatórios que confirmem suas ideologias. \\

Produtores de notícias falsas são empresas com duas características distintas. Primeiro, eles não fazem
investimento em relatórios precisos, de modo que seus sinais subjacentes não sejam correlacionados com
o verdadeiro estado. Em segundo lugar, eles não tentam construir uma reputação de qualidade para longo prazo, mas sim maximizar os lucros de curto prazo de atrair cliques em um determinado período. \\

Adicionar produtores de notícias falsas a um mercado tem vários custos sociais potenciais. Primeiro,
consumidores que confundem uma saída falsa com uma legítima têm crenças menos precisas
e são piores por esse motivo. Em segundo lugar, essas crenças menos precisas podem reduzir
externalidades sociais positivas, minando a capacidade do processo democrático de
selecionar candidatos de alta qualidade. Terceiro, os consumidores também podem se tornar mais céticos
de produtores legítimos de notícias, na medida em que se tornam difíceis de distinguir
de produtores de notícias falsas. Quarto, esses efeitos podem ser reforçados em equilíbrio por
respostas do lado da oferta: uma demanda reduzida por relatórios de alta precisão e baixo viés
reduziria os incentivos para investir em relatórios precisos e sinais de relatórios com veracidade.
Esses efeitos negativos sobrepõem-se diante de qualquer ganho de bem-estar que surja dos consumidores
que gostam de ler notícias falsas consistentes com seus antecedentes.


\subsection{\textit{Fake News detection Using Machine Learning}}

Em \cite{baarir2020} os autores apresentam um método para detecção de \textit{fake news} que utiliza: \\

\begin{enumerate}
    \item \textbf{Pré-processamento de texto} que consiste do uso de \textit{stemmers}, remoção de \textit{stop words} e caracteres especiais;
    \item \textbf{\textit{Encoding} do texto} utilizando modelos de \textit{bag of words}, \textbf{N-gram} e \textit{TF-IDF}
    \item \textbf{Extração de características} que permite uma identificação precisa de informações falsas. Foram utilizados como \textit{features} a fonte da notícia, o autor, a data e o sentimento do texto.
    \item \textbf{\textit{Support Vector Vachine}} Um algoritmo de aprendizado de máquina supervisionado vastamente utilizado em problemas de classificação.
\end{enumerate}


\subsubsection{Sistema proposto}

O sistema proposto usa como entrada uma base de dados de comentarios e metadados, tais como, data, fonte e autor. Essa informação era entçao transformada em \textit{features} que podiam ser usadas na etapa de aprendizagem. 

A base de dados processada era dividida em duas partes: a primeira, que é utilizada para treinamento, e a segunda, que é utilizada para teste. O modulo de treinamento utiliza os dados de treinamento e o algoritmo \textit{SVM} para construir um modelo de decisão que pode ser aplicado a base de dados de teste. Se o modelo for aceito, isto é, for capaz de alcançar um nível de acurácia aceitavel, ele pode ser mantido e utilizado quando o treinamento terminar. Caso contrário, os parametros do algorítmo de aprendizado são tunados de modo a aprimorar a acurácia do modelo. O modelo proposto pode ser visto na Figura \ref{fig:mesh1}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{Imagens/revisao informal/modelo1.png}
    \caption{Modelo de aprendizado}
    \label{fig:mesh1}
\end{figure}



\subsubsection{Pré-processamento}

Na base de dados utilizada, as características das noticias são classificadas em três categorias: dados textuais, dados categóricos e dados numéricos. \\

\textbf{Dados Textuais}: Estes são os dados que representam o texto escrito pelo autor. O pré-processamento desses dados consites das seguintes operações: \\

\begin{enumerate}
    \item \textbf{Limpeza}: Elimina \textit{stop words} e caractéres especiais;
    \item \textbf{\textit{Steming}}: Transforma as palavras úteis em radicais;
    \item \textbf{\textit{Encoding}}: transforma todas as palavras do texto em um vetor numérico. Esta etapa necessita de dois passos: A combinação de duas técnicas, especificamente, \textit{bag-of-words} \cite{gerard1983} e \textit{N-grams} \cite{chris1985}, então a aplicação do método \textit{TF-IDF} \cite{juan2003} no resultado. \\
\end{enumerate} 


\textbf{Dados Categóricos}: 


Dados categóricos. Representam a fonte das notícias tais como canal de TV, jornal ou revista, e seu autor. O pré-tratamento desses dados é realizado através de dois passos:

\begin{enumerate}
    \item \textbf{Limpeza}: eliminando caracteres especiais e transformando os caracteres para \textit{lowercase}.
    \item \textbf{Codificação}:  para fontes foram utilizados uma codificação de \textit{labels}. Por autores, foi criada uma codificação para converter os nomes do autor em números digitais, de modo que autores da mesma fonte estão próximos uns dos outros comparação com autores de outras fontes. \\

\end{enumerate}




\textbf{Dados Numéricos}: Representam a data da notícia e o sentimento dado pelo texto. A data foi utilizada como 3 valores numéricos distintos, o dia, o mês e o ano da postagem da notícia. Para o sentimento dado pelo texto, foi calculado a soma dos graus de sentimento das palavras. De acordo com experts, cada palavra possui um grau de sentimento que permite com que ela seja classificada em três classes: \textit{(i)} Se a soma for menor que zero, o sentimento é negativo; \textit{(ii)} Se a soma for maior que zero, o sentimento é positivo; \textit{(iii)} se a somar for 0, o sentimento é neutro.


\subsubsection{\textit{Dataset}}

O \textit{Dataset} utilizado foi uma combinação de dois \textit{datasets} existentes  "Getting Real about
Fake News" \cite{fakenews2016} e "All the news" \cite{allthenews2017}. Estes \textit{datasets} foram obtidos do website \textit{Kaggle}. Após pré-processar os dois conjuntos de dados e testar os recursos um a um até atingir a melhor taxa de precisão. foi obtido um conjunto de dados que contém as seguintes características:

\begin{itemize}
    \item 5 palavras obtidas pelo método do saco de palavras,
    \item 3 palavras compostas obtidas pelo método N-gram,
    \item data: dia, mês e ano,
    \item sentimento,
    \item fonte,
    \item autor,
    \item classe: falsa ou real. \\
\end{itemize}

\subsubsection{Resultados}



